#!/usr/bin/env python3
"""
Twitter Web3çƒ­ç‚¹è¿½è¸ªå™¨
åŠŸèƒ½ï¼š
1. æ‰«æTwitteræ—¶é—´çº¿ï¼Œæå–Web3ç›¸å…³æŽ¨æ–‡
2. è¯†åˆ«æ–°é¡¹ç›®ã€ç©ºæŠ•ä¿¡æ¯ã€èžèµ„ä¿¡æ¯
3. åˆ†æžé¡¹ç›®ç©ºæŠ•æ½œåŠ›
4. æ¯å¤©ä¸­åˆ12ç‚¹å®šæ—¶å‘é€æŠ¥å‘Š
"""

import asyncio
import json
import re
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from pathlib import Path

class TwitterHotspotTracker:
    def __init__(self):
        self.data_file = Path('/root/clawd/data/twitter_hotspots.json')
        self.data_file.parent.mkdir(parents=True, exist_ok=True)
        
        # Web3å…³é”®è¯åˆ—è¡¨
        self.web3_keywords = {
            'airdrop': ['airdrop', 'ç©ºæŠ•', 'whitelist', 'ç™½åå•', 'claim', 'é¢†ç©º'],
            'new_project': ['launch', 'launching', 'é¦–å‘', 'mainnet', 'æµ‹è¯•ç½‘', 'testnet', 'mainnet', 'v2'],
            'funding': ['funding', 'èžèµ„', 'æŠ•èµ„', 'investment', 'round', 'èžèµ„è½®', 'aè½®', 'bè½®', 'seed', 'ç§å­è½®'],
            'defi': ['defi', 'yield', 'è´¨æŠ¼', 'restake', 'æµåŠ¨æ€§', 'mining', 'æŒ–çŸ¿'],
            'nft': ['nft', 'ç™½åå•', 'wl', 'mint', 'é“¸é€ ', 'å‘è¡Œ', 'blindbox', 'ç›²ç›’'],
            'token': ['token', 'ä»£å¸', 'coin', 'coinlist', 'ä¸Šæ‰€', 'å¸å®‰', 'okx', 'gate', 'binance'],
            'layer2': ['layer2', 'l2', 'rollup', 'zk', 'layer3', 'l3']
        }
        
        # åŠ è½½åŽ†å²æ•°æ®
        self.history = self._load_history()
    
    def _load_history(self) -> Dict:
        """åŠ è½½åŽ†å²æ•°æ®"""
        if self.data_file.exists():
            with open(self.data_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            'last_scan': None,
            'projects': {},
            'trends': {}
        }
    
    def _save_history(self):
        """ä¿å­˜åŽ†å²æ•°æ®"""
        with open(self.data_file, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, ensure_ascii=False, indent=2)
    
    def analyze_post(self, post: Dict) -> Dict:
        """åˆ†æžæŽ¨æ–‡å¹¶æå–çƒ­ç‚¹ä¿¡æ¯"""
        text = post.get('text', '').lower()
        author = post.get('author', '')
        url = post.get('url', '')
        
        result = {
            'text': post.get('text', ''),
            'author': author,
            'url': url,
            'time': post.get('time', ''),
            'categories': [],
            'project_name': None,
            'airdrop_info': None,
            'funding_info': None,
            'potential_score': 0
        }
        
        # åˆ†ç±»æŽ¨æ–‡
        for category, keywords in self.web3_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    result['categories'].append(category)
        
        # æå–é¡¹ç›®åç§°
        project_match = re.search(r'[\"\'ã€Žã€]([a-zA-Z0-9]+)[\"\'ã€ã€‘]', text)
        if project_match:
            result['project_name'] = project_match.group(1)
        
        # æå–ç©ºæŠ•ä¿¡æ¯
        if 'airdrop' in result['categories']:
            airdrop_patterns = [
                r'ç™½åå•[:ï¼š\s*([a-zA-Z0-9]+)',
                r'claim\s*[:ï¼š]\s*([a-zA-Z0-9]+)',
                r'ç©ºæŠ•.*[:ï¼š]\s*([a-zA-Z0-9]+)'
            ]
            for pattern in airdrop_patterns:
                match = re.search(pattern, text)
                if match:
                    result['airdrop_info'] = match.group(1)
        
        # æå–èžèµ„ä¿¡æ¯
        if 'funding' in result['categories']:
            funding_match = re.search(r'([$]\s*[\d.,]+)\s*(ä¸‡|million|billion)', text)
            if funding_match:
                result['funding_info'] = funding_match.group(1) + funding_match.group(2)
        
        # è®¡ç®—æ½œåŠ›åˆ†æ•°
        score = 0
        
        # é«˜æ½œåŠ›æŒ‡æ ‡
        high_potential = [
            ('launch', 3), ('airdrop', 2), ('whitelist', 2), ('coinlist', 2)
        ]
        
        # ä¸­æ½œåŠ›æŒ‡æ ‡
        medium_potential = [
            ('funding', 2), ('testnet', 1), ('testnetæµ‹è¯•ç½‘', 1)
        ]
        
        # ä½Žæ½œåŠ›æŒ‡æ ‡
        low_potential = [
            ('launching', 1), ('mainnet', 1), ('v2', 1)
        ]
        
        for category in result['categories']:
            if category in ['airdrop', 'new_project']:
                for keyword, points in high_potential:
                    if keyword in text:
                        score += points
            elif category in ['funding']:
                for keyword, points in medium_potential:
                    if keyword in text:
                        score += points
            else:
                for keyword, points in low_potential:
                    if keyword in text:
                        score += points
        
        # é¡¹ç›®æ´»è·ƒåº¦åŠ åˆ†
        activity_keywords = ['testnet', 'æµ‹è¯•ç½‘', 'å¿«ç…§', 'snapshot', 'a1', 'a2', 'a3', 'alpha']
        if any(kw in text for kw in activity_keywords):
            score += 2
        
        # å®˜æ–¹è´¦å·åŠ åˆ†
        official_keywords = ['official', 'å®˜æ–¹', 'team', 'å›¢é˜Ÿ', 'dev', 'å¼€å‘']
        if any(kw in text for kw in official_keywords):
            score += 2
        
        result['potential_score'] = min(score, 10)
        
        return result
    
    async def scan_twitter(self) -> List[Dict]:
        """ä½¿ç”¨Playwrightæ‰«æTwitter"""
        print("æ­£åœ¨æ‰«æTwitteræ—¶é—´çº¿...")
        
        try:
            proc = await asyncio.create_subprocess_exec(
                'node',
                [
                    '-e',
                    f"""
const {{ chromium }} = require('playwright');

(async () => {{
  const context = await chromium.launchPersistentContext('/root/.config/google-chrome', {{
    headless: false,
    args: ['--disable-dev-shm-usage', '--no-sandbox']
  }});
  
  const page = await context.newPage();
  await page.goto('https://x.com/home', {{ waitUntil: 'domcontentloaded', timeout: 30000 }});
  await page.waitForTimeout(5000);
  
  // æ»¾åŠ¨3æ¬¡åŠ è½½æ›´å¤šæŽ¨æ–‡
  for (let i = 0; i < 3; i++) {{
    await page.evaluate(() => window.scrollTo(0, document.body.scrollHeight));
    await page.waitForTimeout(2000);
  }}
  
  const posts = await page.evaluate(() => {{
    const tweetElements = document.querySelectorAll('[data-testid="tweet"]');
    const results = [];
    
    for (let tweet of tweetElements) {{
      const textEl = tweet.querySelector('[data-testid="tweetText"]');
      const nameEl = tweet.querySelector('[data-testid="User-Name"]');
      const timeEl = tweet.querySelector('time');
      const linkEl = tweet.querySelector('a[href*="/status/"]');
      
      if (textEl && nameEl) {{
        const text = textEl.innerText;
        const author = nameEl.innerText;
        const url = linkEl ? 'https://x.com' + linkEl.getAttribute('href') : '';
        const time = timeEl ? timeEl.getAttribute('datetime') : '';
        
        results.push({{ text, author, url, time }});
      }}
    }}
    
    return results;
  }});
  
  console.log(JSON.stringify(posts));
  await context.close();
}})();
"""
                ],
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await asyncio.wait_for(proc, timeout=120)
            
            if stdout:
                try:
                    # ä»ŽJSONä¸­æå–æŽ¨æ–‡æ•°æ®
                    json_start = stdout.find('[{')
                    json_end = stdout.rfind('}]') + 1
                    
                    if json_start >= 0 and json_end > json_start:
                        posts_str = stdout[json_start:json_end]
                        posts = json.loads(posts_str)
                        return posts
                except:
                    pass
            
            return []
            
        except asyncio.TimeoutError:
            print("æ‰«æè¶…æ—¶")
            return []
        except Exception as e:
            print(f"æ‰«æé”™è¯¯: {e}")
            return []
    
    def analyze_posts(self, posts: List[Dict]) -> List[Dict]:
        """åˆ†æžæŽ¨æ–‡"""
        analyzed = []
        
        for post in posts:
            result = self.analyze_post(post)
            if result['potential_score'] >= 3:  # åªä¿ç•™æ½œåŠ›>=3çš„
                analyzed.append(result)
        
        return analyzed
    
    def generate_report(self, analyzed_posts: List[Dict]) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        if not analyzed_posts:
            return "ä»Šå¤©æ²¡æœ‰å‘çŽ°é«˜æ½œåŠ›çš„Web3çƒ­ç‚¹"
        
        # æŒ‰æ½œåŠ›åˆ†æ•°æŽ’åº
        sorted_posts = sorted(analyzed_posts, key=lambda x: x['potential_score'], reverse=True)
        
        # åˆ†ç±»å±•ç¤º
        report = f"ðŸ“Š Twitter Web3çƒ­ç‚¹æŠ¥å‘Š\\n"
        report += f"ðŸ“… {datetime.now().strftime('%Y-%m-%d %H:%M')}\\n"
        report += f"ðŸŽ¯ å…±å‘çŽ° {len(analyzed_posts)} ä¸ªé«˜æ½œåŠ›çš„Web3çƒ­ç‚¹\\n\\n"
        
        # é«˜æ½œåŠ›çƒ­ç‚¹ (åˆ†æ•°7-10)
        high_potential = [p for p in sorted_posts if p['potential_score'] >= 7]
        if high_potential:
            report += "ðŸ”¥ðŸ”¥ðŸ”¥ **é«˜æ½œåŠ›çƒ­ç‚¹** ðŸ”¥ðŸ”¥ðŸ”¥\\n"
            for i, post in enumerate(high_potential, 1):
                report += f"\\n{i}. {post['project_name'] or post['author']}\\n"
                report += f"   æ½œåŠ›: {post['potential_score']}/10\\n"
                report += f"   å†…å®¹: {post['text'][:80]}...\\n"
        
        # ä¸­æ½œåŠ›çƒ­ç‚¹ (åˆ†æ•°5-6)
        medium_potential = [p for p in sorted_posts if 5 <= p['potential_score'] <= 6]
        if medium_potential:
            report += "\\nâ­â­â­ **ä¸­æ½œåŠ›çƒ­ç‚¹** â­â­â­\\n"
            for i, post in enumerate(medium_potential, 1):
                report += f"\\n{i}. {post['project_name'] or post['author']}\\n"
                report += f"   æ½œåŠ›: {post['potential_score']}/10\\n"
                report += f"   å†…å®¹: {post['text'][:80]}...\\n"
        
        # ç»Ÿè®¡ä¿¡æ¯
        report += "\\nðŸ“Š **ç»Ÿè®¡ä¿¡æ¯** ðŸ“Š\\n"
        
        # æŒ‰ç±»åž‹ç»Ÿè®¡
        category_count = {}
        for post in analyzed_posts:
            for cat in post['categories']:
                category_count[cat] = category_count.get(cat, 0) + 1
        
        report += f"ç©ºæŠ•ç›¸å…³: {category_count.get('airdrop', 0)}ä¸ª\\n"
        report += f"æ–°é¡¹ç›®: {category_count.get('new_project', 0)}ä¸ª\\n"
        report += f"èžèµ„ä¿¡æ¯: {category_count.get('funding', 0)}ä¸ª\\n"
        
        return report
    
    async def scan_and_report(self):
        """æ‰«æå¹¶å‘é€æŠ¥å‘Š"""
        print("\\n" + "="*50)
        print(f"å¼€å§‹æ‰«æ - {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        print("="*50 + "\\n")
        
        # æ‰«æTwitter
        posts = await self.scan_twitter()
        print(f"\\næ‰«æå®Œæˆï¼ŒèŽ·å–åˆ° {len(posts)} æ¡æŽ¨æ–‡")
        
        # åˆ†æžæŽ¨æ–‡
        analyzed = self.analyze_posts(posts)
        print(f"\\nåˆ†æžå®Œæˆï¼Œå‘çŽ° {len(analyzed)} ä¸ªé«˜æ½œåŠ›çƒ­ç‚¹")
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report(analyzed)
        print("\\n" + report)
        
        # ä¿å­˜æ•°æ®
        self.history['last_scan'] = datetime.now().isoformat()
        self.history['trends'][datetime.now().strftime('%Y-%m-%d')] = analyzed
        self._save_history()
        
        print("\\nâœ… æ•°æ®å·²ä¿å­˜")
        print("ç­‰å¾…æ˜Žå¤©ä¸­åˆ12ç‚¹è‡ªåŠ¨å‘é€...")

async def main():
    tracker = TwitterHotspotTracker()
    
    # æ‰«æå¹¶å‘é€æŠ¥å‘Š
    await tracker.scan_and_report()

if __name__ == "__main__":
    asyncio.run(main())
